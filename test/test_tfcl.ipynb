{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meruozhu/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/meruozhu/Downloads/MP_data/MP_codes/MP')\n",
    "from DPM.task_free_continual_learning.method import Task_free_continual_learning\n",
    "from DPM.task_free_continual_learning.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "from Data.data import Data\n",
    "from edbn.Utils.LogFile import LogFile\n",
    "import edbn.Predictions.setting as setting\n",
    "from edbn import Methods\n",
    "from collections import deque\n",
    "from itertools import islice\n",
    "from collections import OrderedDict\n",
    "from PrefixTreeCDD.PrefixTreeClass import PrefixTree\n",
    "import PrefixTreeCDD.settings as settings\n",
    "from PrefixTreeCDD.CDD import Window\n",
    "from skmultiflow.drift_detection import ADWIN, PageHinkley\n",
    "import math\n",
    "from numpy import log as ln\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import utils as ku\n",
    "import numpy.random as rn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/Helpdesk.csv')\n",
    "# Keep only the first 300 rows\n",
    "df = df[:300]\n",
    "\n",
    "# Adding column for first 150 rows\n",
    "df.loc[df.index[:150], 'new_col'] = df['event'].apply(lambda x: 1 if x == 'Assign seriousness' else 0)\n",
    "\n",
    "# Adding column for last 150 rows\n",
    "df.loc[df.index[-150:], 'new_col'] = df['event'].apply(lambda x: 0 if x == 'Assign seriousness' else 1)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "df.to_csv('/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/Helpdesk_mini.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num events is 300\n",
      "PREPARE\n",
      "CONVERT\n",
      "PREPROCESSING: Converting event\n",
      "PREPROCESSING: Converting role\n",
      "PREPROCESSING: Converting case\n",
      "K-CONTEXT\n",
      "Create k-context: 10\n",
      "SPLIT TRAIN-TEST\n",
      "Train: 150\n",
      "Test: 150\n"
     ]
    }
   ],
   "source": [
    "file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/Helpdesk_mini.csv'\n",
    "data = pd.read_csv(file, low_memory=False)\n",
    "timeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "numEvents = data.shape[0]\n",
    "print(\"Num events is {}\".format(numEvents))\n",
    "\n",
    "dataName = 'Helpdesk_mini'\n",
    "log = LogFile(filename=file, delim=\",\", header=0, rows=None, time_attr=\"completeTime\", trace_attr=\"case\",\n",
    "                    activity_attr='event', convert=False)\n",
    "d = Data(dataName,\n",
    "            LogFile(filename=file, delim=\",\", header=0, rows=None, time_attr=\"completeTime\", trace_attr=\"case\",\n",
    "                    activity_attr='event', convert=False))\n",
    "d.logfile.keep_attributes(['event', 'role', 'completeTime'])\n",
    "m = Methods.get_prediction_method(\"SDL\")\n",
    "s = setting.STANDARD\n",
    "trainPerc = 0.5\n",
    "s.train_percentage = trainPerc * 100\n",
    "# # #\n",
    "d.prepare(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num events is 300\n",
      "PREPARE\n",
      "CONVERT\n",
      "PREPROCESSING: Converting event\n",
      "PREPROCESSING: Converting role\n",
      "PREPROCESSING: Converting case\n",
      "K-CONTEXT\n",
      "Create k-context: 10\n",
      "SPLIT TRAIN-TEST\n",
      "Train: 150\n",
      "Test: 150\n",
      "Test Context Data\n",
      "     level_0  index  event_Prev9  role_Prev9  completeTime_Prev9  case_Prev9  \\\n",
      "0        150    176            0           0                   0          53   \n",
      "1        151    177            0           0                   0          53   \n",
      "2        152    252            0           0                   0          73   \n",
      "3        153    108            0           0                   0          31   \n",
      "4        154    109            0           0                   0          31   \n",
      "..       ...    ...          ...         ...                 ...         ...   \n",
      "145      295    225            0           0                   0          68   \n",
      "146      296    226            0           0                   0          68   \n",
      "147      297    167            0           0                   0          50   \n",
      "148      298    168            0           0                   0          50   \n",
      "149      299    181            0           0                   0          55   \n",
      "\n",
      "     event_Prev8  role_Prev8  completeTime_Prev8  case_Prev8  ...  \\\n",
      "0              0           0                   0          53  ...   \n",
      "1              0           0                   0          53  ...   \n",
      "2              0           0                   0          73  ...   \n",
      "3              0           0                   0          31  ...   \n",
      "4              0           0                   0          31  ...   \n",
      "..           ...         ...                 ...         ...  ...   \n",
      "145            0           0                   0          68  ...   \n",
      "146            0           0                   0          68  ...   \n",
      "147            0           0                   0          50  ...   \n",
      "148            0           0                   0          50  ...   \n",
      "149            0           0                   0          55  ...   \n",
      "\n",
      "          completeTime_Prev1  case_Prev1  event_Prev0  role_Prev0  \\\n",
      "0                          0          53            1           6   \n",
      "1    2010/02/10 07:42:57.000          53            6           6   \n",
      "2    2010/02/16 09:20:28.000          73            7           6   \n",
      "3    2010/01/14 08:52:50.000          31            6           7   \n",
      "4    2010/02/09 14:01:11.000          31            5           7   \n",
      "..                       ...         ...          ...         ...   \n",
      "145                        0          68            0           0   \n",
      "146                        0          68            1           6   \n",
      "147                        0          50            0           0   \n",
      "148                        0          50            1           6   \n",
      "149                        0          55            0           0   \n",
      "\n",
      "          completeTime_Prev0  case_Prev0 event  role             completeTime  \\\n",
      "0    2010/02/10 07:42:57.000          53     6     6  2010/02/16 10:50:53.000   \n",
      "1    2010/02/16 10:50:53.000          53     7     6  2010/02/16 10:50:57.000   \n",
      "2    2010/02/16 09:20:37.000          73     6     6  2010/02/17 07:45:28.000   \n",
      "3    2010/02/09 14:01:11.000          31     5     7  2010/02/17 08:44:53.000   \n",
      "4    2010/02/17 08:44:53.000          31     2     7  2010/02/17 08:44:59.000   \n",
      "..                       ...         ...   ...   ...                      ...   \n",
      "145                        0          68     1     6  2010/03/09 07:06:03.000   \n",
      "146  2010/03/09 07:06:03.000          68     6     6  2010/03/09 07:06:12.000   \n",
      "147                        0          50     1     6  2010/03/09 07:18:19.000   \n",
      "148  2010/03/09 07:18:19.000          50     1     6  2010/03/09 07:18:29.000   \n",
      "149                        0          55     1     2  2010/03/09 08:08:53.000   \n",
      "\n",
      "     case  \n",
      "0      53  \n",
      "1      53  \n",
      "2      73  \n",
      "3      31  \n",
      "4      31  \n",
      "..    ...  \n",
      "145    68  \n",
      "146    68  \n",
      "147    50  \n",
      "148    50  \n",
      "149    55  \n",
      "\n",
      "[150 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 13:24:45.378464: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-13 13:24:45.379476: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_Prev0 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev2 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev3 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev4 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev5 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev6 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev7 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev8 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_Prev9 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev5 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev6 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev7 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev8 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "role_Prev9 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 8)         64          event_Prev0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 8)         64          event_Prev1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 8)         64          event_Prev2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 8)         64          event_Prev3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 8)         64          event_Prev4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 8)         64          event_Prev5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 8)         64          event_Prev6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 8)         64          event_Prev7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 8)         64          event_Prev8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 8)         64          event_Prev9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 9)         81          role_Prev0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 9)         81          role_Prev1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 9)         81          role_Prev2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 9)         81          role_Prev3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 9)         81          role_Prev4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 9)         81          role_Prev5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 9)         81          role_Prev6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 9)         81          role_Prev7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 9)         81          role_Prev8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 9)         81          role_Prev9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 170)       0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "                                                                 embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "                                                                 embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 170)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 8)         1368        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Softmax)                (None, 8)            0           flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,818\n",
      "Trainable params: 2,818\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "120/120 - 82s - loss: 2.0561 - val_loss: 2.0530\n",
      "Epoch 2/5\n",
      "120/120 - 2s - loss: 1.9939 - val_loss: 2.0217\n",
      "Epoch 3/5\n",
      "120/120 - 3s - loss: 1.9089 - val_loss: 1.9794\n",
      "Epoch 4/5\n",
      "120/120 - 2s - loss: 1.8010 - val_loss: 1.9293\n",
      "Epoch 5/5\n",
      "120/120 - 2s - loss: 1.6739 - val_loss: 1.8802\n"
     ]
    }
   ],
   "source": [
    "file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/Helpdesk_mini.csv'\n",
    "data = pd.read_csv(file, low_memory=False)\n",
    "timeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "numEvents = data.shape[0]\n",
    "print(\"Num events is {}\".format(numEvents))\n",
    "\n",
    "dataName = 'Helpdesk_mini'\n",
    "d = Data(dataName,\n",
    "            LogFile(filename=file, delim=\",\", header=0, rows=None, time_attr=\"completeTime\", trace_attr=\"case\",\n",
    "                    activity_attr='event', convert=False))\n",
    "d.logfile.keep_attributes(['event', 'role', 'completeTime'])\n",
    "m = Methods.get_prediction_method(\"SDL\")\n",
    "s = setting.STANDARD\n",
    "trainPerc = 0.5\n",
    "s.train_percentage = trainPerc * 100\n",
    "# # #\n",
    "d.prepare(s)\n",
    "# d.create_batch(\"normal\", timeformat)\n",
    "is_written = 0\n",
    "\n",
    "start_time = time.time()\n",
    "# print(d.train.contextdata)\n",
    "print(\"Test Context Data\")\n",
    "print(d.test_orig.contextdata)\n",
    "basic_model = m.train(d.train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=1.0, \n",
    "\n",
    "ntasks=2\n",
    "dim=4\n",
    "discriminator_offset=0.01\n",
    "distribution_offset=0.01\n",
    "uniform_width=1.25\n",
    "nsamples=500\n",
    "ntrain=40\n",
    "ntest=2\n",
    "# seed\n",
    "rn.seed(512)\n",
    "stime=time.time()\n",
    "tasks={}\n",
    "        \n",
    "# sample points for four tasks related to four quadrants\n",
    "for q in range(ntasks):\n",
    "    #print(\"quadrant {0}\".format(q))\n",
    "    # step 1 sample points in quadrant uniformly from [0:1]\n",
    "    if q == 0: # 1th task\n",
    "        # slice the dataframe to keep all columns except the last one\n",
    "        # xs=data.iloc[:, :-1]\n",
    "        # ys=data.iloc[:, -1]\n",
    "        xs=rn.uniform(distribution_offset,uniform_width,nsamples)\n",
    "        # print('xs',xs,len(xs))\n",
    "        ys=rn.uniform(distribution_offset,uniform_width,nsamples)\n",
    "    elif q == 1: # 2nd task\n",
    "        xs=rn.uniform(-distribution_offset,-uniform_width,nsamples)\n",
    "        ys=rn.uniform(distribution_offset,uniform_width,nsamples)\n",
    "    elif q == 2: # 3th quadrant\n",
    "        xs=rn.uniform(-distribution_offset,-uniform_width,nsamples)\n",
    "        ys=rn.uniform(-distribution_offset,-uniform_width,nsamples)\n",
    "    else: #4th quadrant\n",
    "        xs=rn.uniform(distribution_offset,uniform_width,nsamples)\n",
    "        ys=rn.uniform(-distribution_offset,-uniform_width,nsamples)\n",
    "    samples=[]\n",
    "    for i in range(len(xs)):\n",
    "        sample=[xs[i],ys[i]]\n",
    "        for j in range(dim-2): #add noise gausians in other dimensions\n",
    "            sample.append(rn.uniform(-uniform_width,uniform_width))\n",
    "            #print(sample)\n",
    "        samples.append(sample)\n",
    "    # print('samples',samples)\n",
    "    # print('arrays',np.asarray(samples))\n",
    "    tasks[q]=np.asarray(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.42015664278236897,\n",
       " 0.8506855260539721,\n",
       " -0.5302694932323413,\n",
       " 0.37004551164606125]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:proportion positive/total=0.5\n",
      "1:proportion positive/total=0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs={}\n",
    "labels={}\n",
    "\n",
    "# Step 3: Sample correct distribution given certain alpha\n",
    "for q in range(ntasks):\n",
    "    pos_inputs=[]\n",
    "    neg_inputs=[]\n",
    "    other_tasks=list(range(ntasks))\n",
    "    del other_tasks[q]\n",
    "    while not (len(pos_inputs) == ntrain/2 and len(neg_inputs) == ntrain/2): \n",
    "        if rn.binomial(1,alpha): #1 if original task, 0 if data sampled from 1 of the others.\n",
    "            q_temp=q\n",
    "        else: # pick from random other quadrant\n",
    "            q_temp=rn.choice(other_tasks)\n",
    "        sample=tasks[q_temp][0]\n",
    "        # samples are popped from the distribution to avoid them to be reused.\n",
    "        tasks[q_temp]=tasks[q_temp][1:]\n",
    "        if np.sqrt(np.sum(sample**2))>1+discriminator_offset and len(neg_inputs) < ntrain/2:\n",
    "            neg_inputs.append(sample) \n",
    "        #elif np.sqrt(np.sum(sample**2))<1:\n",
    "        elif np.sqrt(np.sum(sample**2))<1-discriminator_offset and len(pos_inputs) < ntrain/2:\n",
    "            pos_inputs.append(sample) \n",
    "        else: #discard samples on border as task becomes too hard \n",
    "            pass\n",
    "    pos_inputs=pos_inputs[:int(ntrain/2)]\n",
    "    # print(pos_inputs)\n",
    "    neg_inputs=neg_inputs[:int(ntrain/2)]\n",
    "    # print(neg_inputs)\n",
    "    inputs[q]=pos_inputs+neg_inputs\n",
    "    rn.shuffle(inputs[q])\n",
    "    labels[q]=[]\n",
    "    for sample in inputs[q]:\n",
    "        if np.sqrt(np.sum(sample**2))>1+discriminator_offset:\n",
    "            labels[q].append(0) \n",
    "        elif np.sqrt(np.sum(sample**2))<1-discriminator_offset:\n",
    "            labels[q].append(1) \n",
    "        else: #discard samples on border as task becomes too hard \n",
    "            pass\n",
    "    #if verbose: plt.plot(sample[0],sample[1],icon[q])\n",
    "    print('{0}:proportion positive/total={1}'.format(q,float(sum(labels[q]))/len(labels[q])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00628232,  0.45844909,  1.08771111, -0.14832103])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling data duration:  446.4313819408417\n",
      "<class 'dict'> 199\n",
      "<built-in method keys of dict object at 0x7f8dac1d6780>\n",
      "<class 'dict'> [array([ 1.00628232,  0.45844909,  1.08771111, -0.14832103]), array([ 0.15323392,  0.97929753, -1.22531805,  1.18517765]), array([0.11512547, 0.55350968, 0.93751561, 1.08646026]), array([ 0.77614699,  0.08418841, -1.19811774,  1.23385797]), array([ 0.33833774,  0.52128317,  0.39715614, -0.36154088]), array([ 0.07006794,  0.71839165, -0.17742743, -0.16690964]), array([ 0.55793649,  1.04764909,  0.50534306, -0.08130052]), array([ 0.49093612,  0.73437225, -0.76831385, -0.78087616]), array([ 0.53147875,  0.94836833, -0.44182229,  0.73560696]), array([ 0.36582721,  0.71278102,  0.35909352, -0.26635083]), array([0.59866706, 0.11612203, 0.77091497, 0.08967942]), array([ 0.14304687,  0.097595  , -0.62552362,  0.89825062]), array([0.04408643, 0.3862239 , 1.07580303, 0.03786426]), array([ 0.01475308,  0.0130378 ,  0.1076325 , -0.82526596]), array([ 0.27280179,  0.81182781,  1.14625426, -0.3030671 ]), array([ 0.32519446,  0.57773911,  0.05902603, -0.44269665]), array([1.20172595, 0.47729636, 1.15743258, 1.01732196]), array([ 0.97992327,  1.08080721, -1.21317632, -1.04516288]), array([ 0.3308701 ,  0.62096478, -0.18377294, -0.33748352]), array([0.42732649, 0.3494803 , 0.64327151, 1.15603633]), array([ 0.70362571,  0.09447161, -1.23926901,  0.56400939]), array([ 0.2539428 ,  0.07765565, -0.11825683, -0.48435032]), array([ 1.12813515,  0.83002108,  0.81582812, -1.08270166]), array([ 0.11830407,  0.30476441, -0.26902987, -0.7696    ]), array([1.23394085, 0.44409788, 0.90748758, 0.41953054]), array([ 0.346434  ,  0.09127828, -0.08672798, -0.70676325]), array([0.13960104, 0.6940323 , 0.22886532, 0.02983128]), array([ 0.33413122,  0.93611829, -0.99524867, -0.84794383]), array([0.51820615, 0.5037752 , 0.11487452, 0.16946586]), array([ 0.68943558,  0.16813075, -0.29900689,  0.23025457]), array([ 0.05235943,  0.29268734, -0.00190147, -0.37987301]), array([0.13224045, 0.55020326, 0.62367293, 0.42718004]), array([0.56843967, 0.37060029, 0.45456938, 0.50382788]), array([ 0.4627767 ,  0.5738155 ,  0.92762326, -1.17190599]), array([ 0.41623981,  0.1432636 , -0.44630079, -0.45422134]), array([ 0.09410441,  0.3777443 , -0.47144007, -0.62846395]), array([ 0.02805671,  0.34390372, -0.65261236, -0.31090717]), array([ 0.59273398,  0.81307023, -0.89066021, -0.85601184]), array([ 0.84169614,  0.30933866, -0.89787663,  1.16855303]), array([ 0.10436594,  0.15740582, -0.52438214, -0.48317286])] 40\n",
      "<class 'dict'> [0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1] 40\n"
     ]
    }
   ],
   "source": [
    "test_inputs={}\n",
    "test_labels={}\n",
    "for q in range(ntasks):\n",
    "    test_inputs_pos=[]\n",
    "    test_inputs_neg=[]\n",
    "    while len(test_inputs_pos)<ntest/2 or len(test_inputs_neg)<ntest/2:\n",
    "        sample=tasks[q][0]\n",
    "        tasks[q]=tasks[q][1:]\n",
    "        # map sample to 2D plane for visualizations\n",
    "        if len(sample)>2: sample[2:]=0\n",
    "        if np.sqrt(np.sum(sample**2)) > 1+discriminator_offset:\n",
    "            test_inputs_neg.append(sample)\n",
    "            #test_inputs[q].append(sample)\n",
    "            #test_labels[q].append(0)\n",
    "        #elif np.sqrt(np.sum(sample**2)) < 1:\n",
    "        elif np.sqrt(np.sum(sample**2)) < 1-discriminator_offset:\n",
    "            test_inputs_pos.append(sample)\n",
    "            #test_inputs[q].append(sample)\n",
    "            #test_labels[q].append(1)\n",
    "        else:\n",
    "            pass\n",
    "    test_inputs[q]=np.asarray(test_inputs_pos[:int(ntest/2)]+test_inputs_neg[:int(ntest/2)])\n",
    "    test_labels[q]=[1]*int(ntest/2)+[0]*int(ntest/2)\n",
    "    #print test_inputs[q].shape\n",
    "# Check distribution\n",
    "# for q in range(ntasks):\n",
    "#     positive_points=[test_inputs[q][i] for i in range(len(test_inputs[q])) if test_labels[q][i]==1]\n",
    "#     negative_points=[test_inputs[q][i] for i in range(len(test_inputs[q])) if test_labels[q][i]==0]\n",
    "\n",
    "#     if verbose: plt.scatter([p[0] for p in positive_points],[p[1] for p in positive_points],color='blue')\n",
    "#     if verbose: plt.scatter([p[0] for p in negative_points],[p[1] for p in negative_points],color='red')\n",
    "# if verbose: plt.show()\n",
    "print(\"sampling data duration: \",time.time()-stime)\n",
    "\n",
    "print(type(tasks),len(tasks[0]))\n",
    "print(tasks.keys)\n",
    "print(type(inputs),inputs[0],len(inputs[0]))\n",
    "print(type(labels),labels[0],len(labels[0]))\n",
    "# print(test_inputs)\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=d.train.get_data()\n",
    "# Adding column for first 150 rows\n",
    "df.loc[df.index[:150], 'new_col'] = df['event'].apply(lambda x: 1 if x == 'Assign seriousness' else 0)\n",
    "\n",
    "# Adding column for last 150 rows\n",
    "df.loc[df.index[-150:], 'new_col'] = df['event'].apply(lambda x: 0 if x == 'Assign seriousness' else 1)\n",
    "x = df.drop('new_col', axis=1)\n",
    "x = x.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(log, columns):\n",
    "    num_activities = len(log.values[log.activity]) + 1\n",
    "\n",
    "    col_num_vals = {}\n",
    "    for col in columns:\n",
    "        if col == log.activity:\n",
    "            col_num_vals[col] = num_activities\n",
    "        else:\n",
    "            col_num_vals[col] = log.contextdata[col].max() + 2\n",
    "\n",
    "    inputs = []\n",
    "    for _ in range(len(columns) * log.k - len(log.ignoreHistoryAttributes) * log.k):\n",
    "        inputs.append([])\n",
    "    outputs = []\n",
    "    for row in log.contextdata.iterrows():\n",
    "        row = row[1]\n",
    "        i = 0\n",
    "        for attr in columns:\n",
    "            if attr not in log.ignoreHistoryAttributes:\n",
    "                for k in range(log.k):\n",
    "                    inputs[i].append(row[attr + \"_Prev%i\" % k])\n",
    "                    i += 1\n",
    "        outputs.append(row[log.activity])\n",
    "\n",
    "    outputs = ku.to_categorical(outputs, num_activities)\n",
    "    for i in range(len(inputs)):\n",
    "        inputs[i] = np.array(inputs[i])\n",
    "    return inputs, outputs, col_num_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, vals= transform_data(d.train, [a for a in d.train.attributes() if a != d.train.time and a != d.train.trace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 6, 0, 0, 1, 6, 0, 1, 6, 0, 1,\n",
       "        6, 0, 0, 0, 1, 1, 0, 1, 1, 6, 0, 1, 0, 1, 6, 0, 1, 6, 1, 6, 0, 1,\n",
       "        6, 0, 6, 1, 1, 6, 5, 5, 6, 1, 6, 0, 1, 6, 1, 6, 1, 0, 0, 0, 1, 6,\n",
       "        0, 0, 0, 1, 1, 6, 0, 1, 0, 1, 6, 0, 1, 1, 6, 0, 0, 1, 6, 1, 6, 0,\n",
       "        0, 6, 0, 1, 6, 0, 1, 6, 7, 0, 0, 1, 6, 1, 0, 1, 6, 0, 1, 6, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 6, 0, 0, 1, 6, 5, 6, 1, 5, 2, 5, 2, 5, 5, 1,\n",
       "        1, 6, 1, 6, 1, 1, 0, 1, 6, 5, 1, 6, 0, 1, 6, 0, 1, 6]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 6, 6, 5, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 5, 0, 0, 1, 0, 0, 1, 6, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 6, 1, 0, 6, 5, 6, 5, 6, 6, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 1, 6, 1, 1, 0, 0, 1, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 6, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 1, 6, 1, 6, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 0, 6, 6, 0, 6,\n",
       "        4, 0, 0, 0, 6, 6, 0, 6, 6, 6, 0, 6, 0, 6, 6, 0, 6, 2, 6, 6, 0, 6,\n",
       "        6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 0, 0, 0, 6, 6,\n",
       "        0, 0, 0, 6, 6, 6, 0, 6, 0, 6, 6, 0, 6, 6, 6, 0, 0, 6, 6, 6, 6, 0,\n",
       "        0, 6, 0, 5, 5, 0, 5, 5, 5, 0, 0, 6, 6, 6, 0, 6, 6, 0, 6, 6, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6, 6, 6,\n",
       "        6, 6, 6, 1, 6, 6, 0, 6, 1, 6, 6, 6, 0, 6, 6, 0, 6, 6]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 6, 0, 0, 6, 0, 6,\n",
       "        6, 0, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 0, 6, 0, 0, 6, 0, 6, 0, 0,\n",
       "        6, 0, 6, 0, 6, 6, 6, 6, 6, 0, 6, 0, 0, 6, 0, 6, 6, 0, 0, 0, 0, 6,\n",
       "        0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 0, 0, 0, 6, 0, 6, 0,\n",
       "        0, 6, 0, 0, 5, 0, 0, 5, 5, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 6, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 0,\n",
       "        6, 6, 6, 6, 0, 0, 0, 0, 6, 6, 6, 6, 0, 0, 6, 0, 0, 6]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        6, 0, 0, 0, 0, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 6, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 6, 6, 6, 6, 6, 6, 0,\n",
       "        0, 6, 0, 6, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 6, 0, 6, 0, 6, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08845771, 0.25655437, 0.08241332, 0.09202303, 0.09101397,\n",
       "       0.13982287, 0.16602792, 0.08368681], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model.predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(d.test_orig.get_data())):\n",
    "    sample = []\n",
    "    for j in range(len(x)):\n",
    "        sample.append(np.array([x[j][i]]))\n",
    "        #sample.append(x[j][i])\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([6]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([6]),\n",
       " array([6]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.int64'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected event_Prev0 to have 2 dimensions, but got array with shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m_/vqx5l_qd50xbdyfwyvj3dnf40000gn/T/ipykernel_37839/2937184477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 715\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    716\u001b[0m     return predict_loop(\n\u001b[1;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected event_Prev0 to have 2 dimensions, but got array with shape ()"
     ]
    }
   ],
   "source": [
    "np.argmax(basic_model.predict(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_single_sample(model, log):\n",
    "    inputs, expected, _ = transform_data(log, [a for a in log.attributes() if a != log.time and a != log.trace])\n",
    "    predictions = model.predict(inputs)\n",
    "    predict_vals = np.argmax(predictions, axis=1)\n",
    "    return predict_vals\n",
    "predict_single_sample(basic_model, d.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, log):\n",
    "    inputs, expected, _ = transform_data(log, [a for a in log.attributes() if a != log.time and a != log.trace])\n",
    "    predictions = model.predict(inputs)\n",
    "    predict_vals = np.argmax(predictions, axis=1)\n",
    "    predict_probs = predictions[np.arange(predictions.shape[0]), predict_vals]\n",
    "    expected_vals = np.argmax(expected, axis=1)\n",
    "    expected_probs = predictions[np.arange(predictions.shape[0]), expected_vals]\n",
    "    result = zip(expected_vals, predict_vals, predict_probs, expected_probs)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_object=Task_free_continual_learning(verbose=False,\n",
    "                                                        seed=123,\n",
    "                                                        dev='cpu',\n",
    "                                                        dim=4,\n",
    "                                                        hidden_units=100,\n",
    "                                                        learning_rate=0.005,\n",
    "                                                        ntasks=2,\n",
    "                                                        gradient_steps=5,\n",
    "                                                        loss_window_length=5,\n",
    "                                                        loss_window_mean_threshold=0.2,\n",
    "                                                        loss_window_variance_threshold=0.1,                                                         \n",
    "                                                        MAS_weight=0.5,\n",
    "                                                        recent_buffer_size=20,\n",
    "                                                        hard_buffer_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:proportion positive/total=0.5\n",
      "1:proportion positive/total=0.5\n",
      "sampling data duration:  0.06032299995422363\n",
      "tensor([[ 0.9366,  0.0674],\n",
      "        [ 1.1033, -0.0679],\n",
      "        [ 1.0133,  0.0115],\n",
      "        [ 1.0774, -0.0627],\n",
      "        [-0.0017,  1.0195],\n",
      "        [-0.0291,  1.0172],\n",
      "        [ 0.7884,  0.1926],\n",
      "        [ 0.7779,  0.1918],\n",
      "        [ 0.8406,  0.1191],\n",
      "        [ 0.1016,  0.9207],\n",
      "        [ 0.0942,  0.9216],\n",
      "        [ 0.8361,  0.1759],\n",
      "        [ 0.7621,  0.2222],\n",
      "        [-0.0267,  1.0339],\n",
      "        [ 1.0613, -0.0415],\n",
      "        [-0.0106,  1.0170],\n",
      "        [ 1.0689, -0.0546],\n",
      "        [ 1.0953, -0.0666],\n",
      "        [ 0.0243,  0.9706],\n",
      "        [ 0.8838,  0.1358]], grad_fn=<MmBackward>)\n",
      "(20, 2)\n",
      "tensor([[ 0.9473,  0.0685],\n",
      "        [-0.0768,  1.0691],\n",
      "        [ 1.1499, -0.1261],\n",
      "        [ 0.1593,  0.8337],\n",
      "        [ 0.9288,  0.0392],\n",
      "        [ 0.0564,  0.9339],\n",
      "        [ 0.0657,  0.9394],\n",
      "        [ 1.0205, -0.0458],\n",
      "        [ 0.0235,  0.9461],\n",
      "        [ 0.0083,  0.9552],\n",
      "        [-0.1178,  1.1111],\n",
      "        [ 0.2566,  0.7549],\n",
      "        [ 0.1251,  0.8695],\n",
      "        [ 1.0570, -0.0407],\n",
      "        [ 0.0544,  0.9462],\n",
      "        [ 0.2188,  0.7801],\n",
      "        [ 0.1370,  0.8687],\n",
      "        [ 0.9943, -0.0071],\n",
      "        [ 1.0807, -0.1207],\n",
      "        [ 0.0628,  0.9434],\n",
      "        [ 0.1785,  0.8166],\n",
      "        [ 0.9067,  0.0625],\n",
      "        [ 0.1662,  0.8134],\n",
      "        [ 1.1204, -0.1446],\n",
      "        [ 0.8448,  0.0996]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0104,  0.0118],\n",
      "        [ 0.0314,  0.9903],\n",
      "        [ 0.9403,  0.0846],\n",
      "        [ 0.0854,  0.9209],\n",
      "        [ 1.0997, -0.0277],\n",
      "        [ 0.6476,  0.3134],\n",
      "        [ 0.9860,  0.0359],\n",
      "        [ 0.8845,  0.0996],\n",
      "        [ 0.0226,  1.0065],\n",
      "        [ 0.2127,  0.7912],\n",
      "        [ 0.8879,  0.1448],\n",
      "        [-0.0889,  1.0947],\n",
      "        [ 1.0311,  0.0076],\n",
      "        [-0.0030,  1.0271],\n",
      "        [ 0.9335,  0.0931],\n",
      "        [ 0.8074,  0.1143],\n",
      "        [ 0.5818,  0.4313],\n",
      "        [ 0.0582,  0.9344],\n",
      "        [ 1.0573, -0.0582],\n",
      "        [ 0.0138,  0.9742],\n",
      "        [ 0.7538,  0.2215],\n",
      "        [ 0.9288,  0.0634],\n",
      "        [-0.2197,  1.2327],\n",
      "        [ 0.7887,  0.1936],\n",
      "        [-0.1564,  1.1690]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.2984, -0.2809],\n",
      "        [ 1.0671, -0.0538],\n",
      "        [ 0.9465,  0.0256],\n",
      "        [ 0.1277,  0.8607],\n",
      "        [ 0.9600,  0.0061],\n",
      "        [ 0.2199,  0.7884],\n",
      "        [-0.0331,  1.0076],\n",
      "        [ 0.1711,  0.8116],\n",
      "        [ 1.0604, -0.0948],\n",
      "        [ 0.0279,  0.9732],\n",
      "        [-0.0447,  1.0526],\n",
      "        [ 0.0384,  0.9482],\n",
      "        [ 1.1431, -0.1372],\n",
      "        [ 0.1610,  0.8312],\n",
      "        [ 1.0433, -0.0455],\n",
      "        [ 0.2015,  0.7795],\n",
      "        [ 0.1436,  0.8470],\n",
      "        [ 0.1970,  0.7900],\n",
      "        [ 0.2776,  0.6837],\n",
      "        [ 0.8119,  0.1242],\n",
      "        [ 0.3902,  0.5959],\n",
      "        [ 0.1625,  0.8193],\n",
      "        [ 0.1439,  0.8557],\n",
      "        [ 0.7848,  0.2035],\n",
      "        [ 0.1658,  0.8082]], grad_fn=<MmBackward>)\n",
      "duration: 0.01661366621653239minutes, count updates: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, 1.0, 1.0],\n",
       " [0.6324362, 0.6523496, 0.9522458, 0.9746931],\n",
       " [0, 0, 0, 0],\n",
       " [0.0, 0.0003965425, 0.18013982, 0.13661651],\n",
       " {0: [1.0, 1.0, 1.0, 1.0], 1: [0.5, 1.0, 0.5, 0.5]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_object.method(Sampler(),use_hard_buffer=True,continual_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tasks[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14288676,  0.80488097,  0.34772433, -0.61486341])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tasks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m_/vqx5l_qd50xbdyfwyvj3dnf40000gn/T/ipykernel_37839/310664915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "data.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.labels[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmGrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
