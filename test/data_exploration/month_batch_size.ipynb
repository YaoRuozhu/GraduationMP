{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/meruozhu/Downloads/MP_data/MP_codes/MP')\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from scipy.stats import percentileofscore\n",
    "from Data.data import Data\n",
    "from edbn.Utils.LogFile import LogFile\n",
    "import edbn.Predictions.setting as setting\n",
    "from edbn import Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num events is 262628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meruozhu/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/ipykernel_launcher.py:18: DtypeWarning: Columns (6,22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "/Users/meruozhu/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/ipykernel_launcher.py:21: DtypeWarning: Columns (6,22) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARE\n",
      "CONVERT\n",
      "PREPROCESSING: Converting event\n",
      "PREPROCESSING: Converting case\n",
      "K-CONTEXT\n",
      "Create k-context: 10\n",
      "SPLIT TRAIN-TEST\n",
      "Train: 0\n",
      "Test: 262628\n",
      "data prepared done\n"
     ]
    }
   ],
   "source": [
    "# file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/sudden_drift/BPIC17_new.csv'\n",
    "# file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/test_dataset/DomesticDeclarations_mini.csv'\n",
    "# file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/sudden_drift/Hospital+BPI12_new.csv'\n",
    "file='/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/sudden_drift/BPIC15ALL.csv'\n",
    "data = pd.read_csv(file, low_memory=False)\n",
    "timeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "numEvents = data.shape[0]\n",
    "print(\"Num events is {}\".format(numEvents))\n",
    "\n",
    "# Extract the filename from the file path\n",
    "filename = os.path.basename(file)\n",
    "\n",
    "# Remove the file extension from the filename\n",
    "dataName = os.path.splitext(filename)[0]\n",
    "\n",
    "#dataName = 'Helpdesk_mini'\n",
    "log = LogFile(filename=file, delim=\",\", header=0, rows=None, time_attr=\"completeTime\", trace_attr=\"case\",\n",
    "                    activity_attr='event', convert=False)\n",
    "d = Data(dataName,\n",
    "            LogFile(filename=file, delim=\",\", header=0, rows=None, time_attr=\"completeTime\", trace_attr=\"case\",\n",
    "                    activity_attr='event', convert=False))\n",
    "d.logfile.keep_attributes(['event', 'completeTime'])\n",
    "m = Methods.get_prediction_method(\"SDL\")\n",
    "s = setting.STANDARD\n",
    "trainPerc = 0\n",
    "s.train_percentage = trainPerc * 100\n",
    "# # #\n",
    "d.prepare(s)\n",
    "print('data prepared done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make mini dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mini = data.iloc[:300, :]\n",
    "data_mini.to_csv('/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/test_dataset/BPIC15ALL_mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2009-11-18 00:00:00\n",
      "1         2009-11-23 00:00:00\n",
      "2         2010-01-01 00:00:00\n",
      "3         2010-05-13 00:00:00\n",
      "4         2010-06-29 00:00:00\n",
      "                 ...         \n",
      "262623    2015-03-05 00:00:00\n",
      "262624    2015-03-05 00:00:00\n",
      "262625    2015-03-09 00:00:00\n",
      "262626    2015-03-09 00:00:00\n",
      "262627    2015-08-01 00:00:00\n",
      "Name: completeTime, Length: 262628, dtype: object\n",
      "The time format is: %Y-%m-%d %H:%M:%S\n",
      "timeformat %Y-%m-%d %H:%M:%S\n"
     ]
    }
   ],
   "source": [
    "connect_symbol=\"-\"\n",
    "if '/' in d.logfile.get_data()['completeTime'][0]:\n",
    "    connect_symbol='/'\n",
    "formats = [f\"%Y{connect_symbol}%m{connect_symbol}%d %H:%M:%S%z\", f'%Y{connect_symbol}%m{connect_symbol}%d %H:%M:%S',f'%Y{connect_symbol}%m{connect_symbol}%d %H:%M:%S.%f']\n",
    "\n",
    "for timeformat in formats:\n",
    "    try:\n",
    "        pd.to_datetime(d.logfile.get_data()['completeTime'], format=timeformat,exact=True)\n",
    "        print(d.logfile.get_data()['completeTime'])\n",
    "        print(\"The time format is:\", timeformat)\n",
    "        break\n",
    "    except ValueError:\n",
    "        continue\n",
    "print('timeformat',timeformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check monthly batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2009-11-18 00:00:00\n",
      "1         2009-11-23 00:00:00\n",
      "2         2010-01-01 00:00:00\n",
      "3         2010-05-13 00:00:00\n",
      "4         2010-06-29 00:00:00\n",
      "                 ...         \n",
      "262623    2015-03-05 00:00:00\n",
      "262624    2015-03-05 00:00:00\n",
      "262625    2015-03-09 00:00:00\n",
      "262626    2015-03-09 00:00:00\n",
      "262627    2015-08-01 00:00:00\n",
      "Name: completeTime, Length: 262628, dtype: object\n",
      "The time format is: %Y-%m-%d %H:%M:%S\n",
      "timeformat %Y-%m-%d %H:%M:%S\n"
     ]
    }
   ],
   "source": [
    "connect_symbol=\"-\"\n",
    "if '/' in d.logfile.get_data()['completeTime'][0]:\n",
    "    connect_symbol='/'\n",
    "formats = [f\"%Y{connect_symbol}%m{connect_symbol}%d %H:%M:%S%z\", f'%Y{connect_symbol}%m{connect_symbol}%d %H:%M:%S',f'%Y{connect_symbol}%m{connect_symbol}%d %H:%M:%S.%f']\n",
    "\n",
    "for timeformat in formats:\n",
    "    try:\n",
    "        pd.to_datetime(d.logfile.get_data()['completeTime'], format=timeformat,exact=True)\n",
    "        print(d.logfile.get_data()['completeTime'])\n",
    "        print(\"The time format is:\", timeformat)\n",
    "        break\n",
    "    except ValueError:\n",
    "        continue\n",
    "print('timeformat',timeformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.create_batch(split='month',timeformat=timeformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009/11 2\n",
      "2010/01 1\n",
      "2010/05 1\n",
      "2010/06 1\n",
      "2010/10 821\n",
      "2010/11 2344\n",
      "2010/12 4119\n",
      "2011/01 4924\n",
      "2011/02 4813\n",
      "2011/03 5713\n",
      "2011/04 5826\n",
      "2011/05 6144\n",
      "2011/06 6591\n",
      "2011/07 5395\n",
      "2011/08 5564\n",
      "2011/09 4911\n",
      "2011/10 5852\n",
      "2011/11 5201\n",
      "2011/12 5475\n",
      "2012/01 5218\n",
      "2012/02 4997\n",
      "2012/03 5770\n",
      "2012/04 4385\n",
      "2012/05 4092\n",
      "2012/06 5144\n",
      "2012/07 4881\n",
      "2012/08 4992\n",
      "2012/09 4911\n",
      "2012/10 5606\n",
      "2012/11 5167\n",
      "2012/12 4608\n",
      "2013/01 5963\n",
      "2013/02 4203\n",
      "2013/03 7013\n",
      "2013/04 5273\n",
      "2013/05 5371\n",
      "2013/06 6311\n",
      "2013/07 3493\n",
      "2013/08 5143\n",
      "2013/09 4256\n",
      "2013/10 5145\n",
      "2013/11 4865\n",
      "2013/12 4366\n",
      "2014/01 4216\n",
      "2014/02 4576\n",
      "2014/03 4878\n",
      "2014/04 4073\n",
      "2014/05 4380\n",
      "2014/06 4484\n",
      "2014/07 5513\n",
      "2014/08 3376\n",
      "2014/09 5337\n",
      "2014/10 5388\n",
      "2014/11 4934\n",
      "2014/12 4907\n",
      "2015/01 5385\n",
      "2015/02 5583\n",
      "2015/03 726\n",
      "2015/08 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4451.322033898305"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_batch_size_list = []  # the number of activities in each month\n",
    "for key,value in d.test.items():\n",
    "    print(key,value['data'].get_data().shape[0])\n",
    "    month_batch_size_list.append(value['data'].get_data().shape[0])\n",
    "month_batch_size = np.average(np.array(month_batch_size_list))\n",
    "month_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/sudden_drift/Hospital+BPI12_new.csv'\n",
    "file = '/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/sudden_drift/BPIC17_new.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_monthly_events(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert the \"completeTime\" column to a datetime object\n",
    "    df['completeTime'] = pd.to_datetime(df['completeTime'], errors='coerce')\n",
    "\n",
    "    # Extracting the month and year from the \"completeTime\" column\n",
    "    df['month_year'] = df['completeTime'].dt.to_period('M')\n",
    "\n",
    "    # Grouping by the month and year and counting the number of events\n",
    "    monthly_events = df.groupby('month_year').size()\n",
    "\n",
    "    # Calculating the average number of events per month\n",
    "    avg_events_per_month = monthly_events.mean()\n",
    "\n",
    "    return avg_events_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meruozhu/opt/anaconda3/envs/pmGrad/lib/python3.7/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (6,22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4451.322033898305"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_monthly_events(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drift_locations(file_path):\n",
    "    # Extracting data name from the file path\n",
    "    data_name = file_path.split('/')[-1].replace('.csv', '')\n",
    "\n",
    "    # Reading the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Finding the unique cases and calculating the drift interval\n",
    "    num_unique_cases = df['case'].nunique()\n",
    "    print(\"Num unique cases:\", num_unique_cases)\n",
    "    drift_interval = num_unique_cases // 10\n",
    "\n",
    "    # Finding the drift locations based on the drift interval\n",
    "    drift_locations = []\n",
    "    case_count = 0\n",
    "    previous_case = None\n",
    "    for index, row in df.iterrows():\n",
    "        current_case = row['case']\n",
    "        if current_case != previous_case:\n",
    "            case_count += 1\n",
    "            if case_count % drift_interval == 0:\n",
    "                drift_locations.append(index)\n",
    "        previous_case = current_case\n",
    "\n",
    "    return data_name, drift_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recursevely check dataset size and monthly batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unique cases: 5000\n",
      "OIR5000.csv ('OIR5000', [5212, 11033, 16235, 22165, 27314, 33174, 38341, 44256, 49443, 55322])\n",
      "Num unique cases: 5000\n",
      "ROI5000.csv ('ROI5000', [5212, 10354, 15555, 20740, 25888, 31192, 36354, 41555, 46737, 51987])\n",
      "Num unique cases: 5000\n",
      "IOR5000.csv ('IOR5000', [5212, 10460, 15662, 20990, 26138, 31420, 36583, 41841, 47027, 52311])\n",
      "Num unique cases: 5000\n",
      "ORI5000.csv ('ORI5000', [5212, 10988, 16189, 21939, 27089, 32943, 38111, 43746, 48934, 54604])\n",
      "Num unique cases: 5000\n",
      "RIO5000.csv ('RIO5000', [5212, 10663, 15868, 21403, 26553, 32105, 37273, 42765, 47953, 53418])\n",
      "Num unique cases: 5000\n",
      "IRO5000.csv ('IRO5000', [5212, 10741, 15949, 21449, 26593, 32154, 37316, 42941, 48123, 53639])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path\n",
    "dir_path = \"/Users/meruozhu/Downloads/MP_data/MP_codes/MP/Data/synthetic_dataset\"\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    # Check if the filename ends with \"5000.csv\"\n",
    "    if filename.endswith(\"5000.csv\"):\n",
    "        # Construct the full path to the file\n",
    "        full_path = os.path.join(dir_path, filename)\n",
    "        # Count the number of rows without the header\n",
    "        # with open(full_path, 'r') as file:\n",
    "        #     reader = csv.reader(file)\n",
    "        #     next(reader)  # Skip the header\n",
    "        #     row_count = sum(1 for row in reader)\n",
    "        #     print(f\"{filename} has {row_count} rows (excluding header).\")\n",
    "        # ame = average_monthly_events(full_path)\n",
    "        # print(f\"{filename}: {ame}\")\n",
    "        dl = get_drift_locations(full_path)\n",
    "        print(filename, dl)\n",
    "        # Now you can process the file using its full path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmGrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
